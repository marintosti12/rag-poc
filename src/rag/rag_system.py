import re
from langchain_mistralai import ChatMistralAI
from langchain_core.prompts import ChatPromptTemplate
from typing import List, Dict
import os
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()

class RAGSystem:    
    def __init__(self, 
                 vector_store,
                 model_name: str = "mistral-medium-2508",
                 temperature: float = 0.0):
        
        self.vector_store = vector_store
        
        api_key = os.getenv("MISTRAL_API_KEY")
        if not api_key:
            raise ValueError("MISTRAL_API_KEY non trouv√©e dans .env")
        
        self.llm = ChatMistralAI(
            model=model_name,
            temperature=temperature,
            api_key=api_key
        )
        
        self.prompt_template = self._create_prompt_template()
        
        print(f"‚úì Syst√®me RAG initialis√©")
        print(f"  Mod√®le : {model_name}")
        print(f"  Temp√©rature : {temperature}")
    

    def _create_prompt_template(self) -> ChatPromptTemplate:
        from datetime import datetime
        today_iso = datetime.now().astimezone().isoformat(timespec='seconds')

        template = f"""Tu es un assistant d'√©v√©nements. 
    DATE ACTUELLE (ISO, Europe/Paris): {today_iso}

    Tu re√ßois :
    - CONTEXTE = liste d‚Äô√©v√©nements candidats (texte, avec lignes "Titre:", "Date:", "Ville:", "Lieu:", "URL:", "Description:")
    - QUESTION = la demande utilisateur

    OBJECTIF
    - Ne r√©ponds qu‚Äôavec des √©v√©nements du CONTEXTE.
    - Si la QUESTION contient des indices de futur (¬´ bient√¥t ¬ª, ¬´ √† venir ¬ª, ¬´ futurs ¬ª, ¬´ prochain(s) ¬ª, ¬´ upcoming ¬ª, ¬´ next ¬ª, ¬´ this week/end ¬ª), n‚Äôaffiche aucun √©v√©nement strictement ant√©rieur √† la DATE ACTUELLE.
    - Si une date/p√©riode explicite est dans la QUESTION, respecte-la. Sinon, privil√©gie les √©v√©nements √† venir.
    - Respecte un √©ventuel SUJET/GENRE (jazz, th√©√¢tre, expo, etc.).

    D√âTECTION D‚ÄôANN√âE (si la QUESTION contient une ann√©e AAAA)
    1) S√©lectionne en priorit√© les √©v√©nements dont la m√©tadonn√©e `year` == AAAA.
    2) Sinon, utilise l‚Äôann√©e de `date_start`.
    3) Sinon, si l‚Äôann√©e AAAA appara√Æt dans le texte du CONTEXTE (ex. "DateISO:" ou "Date:"), consid√®re ces √©v√©nements comme correspondants.
    4) S‚Äôil y a plusieurs correspondances, garde les plus pertinentes (et les plus proches en date).

    ‚ö†Ô∏è IMPORTANT
    - N‚Äô√©cris **jamais** la phrase d‚Äô√©chec si le CONTEXTE contient au moins 1 √©v√©nement : dans ce cas, rends **toujours** un tableau Markdown avec les meilleurs candidats (m√™me si la correspondance n‚Äôest pas parfaite).
    - N‚Äô√©cris la phrase **exacte** "Je n'ai trouv√© aucun √©v√©nement correspondant √† votre recherche." **que si** apr√®s application des r√®gles ci-dessus, tu n‚Äôas **strictement aucun** √©v√©nement √† afficher.

    R√àGLES DE TRI
    - Tri par date croissante (la plus proche d‚Äôabord).
    - √Ä date √©gale, privil√©gie le meilleur match s√©mantique au sujet demand√©.

    R√àGLES DE SORTIE (TOUJOURS)
    - Sortie **UNIQUEMENT en Markdown** (pas d‚Äôintro, pas de conclusion).
    - **Toujours** afficher un **tableau Markdown** si tu as ‚â• 1 √©v√©nement :
    | Date | Titre | Ville | Lieu | Lien |
    - Remplissage :
    - **Date** : convertir ISO ‚Üí **JJ/MM/AAAA HH:MM** (24h). Si l‚Äôheure manque, mettre **JJ/MM/AAAA**.
    - **Titre** : titre exact.
    - **Ville** et **Lieu** : tels que dans le CONTEXTE (laisser vide si manquants).
    - **Lien** : **[Lien](URL)** ; vide si URL manquante.
    - Interdits : ‚Äú---‚Äù, blocs de code, texte hors format, colonnes suppl√©mentaires.
    - N‚Äôinvente rien.

    CONVERSION DE LA DATE
    - Le CONTEXTE peut contenir des dates ISO (ex: 2026-03-29T10:00:00+02:00). Convertis-les en JJ/MM/AAAA HH:MM (24h).
    - Si l‚Äôheure manque, affiche seulement JJ/MM/AAAA.

    === CONTEXTE (√©v√©nements candidats) ===
    {{context}}

    === QUESTION UTILISATEUR ===
    {{question}}
    """
        return ChatPromptTemplate.from_template(template)



    
    def _format_documents(self, results: List[tuple]) -> str:        
        context_parts = []
        
        months_fr = {
            1: 'janvier', 2: 'f√©vrier', 3: 'mars', 4: 'avril',
            5: 'mai', 6: 'juin', 7: 'juillet', 8: 'ao√ªt',
            9: 'septembre', 10: 'octobre', 11: 'novembre', 12: 'd√©cembre'
        }
        
        for i, (doc, score) in enumerate(results, 1):
            metadata = doc['metadata']
            
            date_str = metadata.get('date_start', 'N/A')
            date_readable = date_str
            
            if date_str != 'N/A':
                try:
                    dt = datetime.fromisoformat(date_str.replace('Z', '+00:00'))
                    date_readable = f"{dt.day} {months_fr[dt.month]} {dt.year} ({date_str})"
                except:
                    pass
            
            event_info = f"""=== √âV√âNEMENT {i} ===
Titre: {metadata.get('title', 'N/A')}
üìÖ DATE EXACTE: {date_readable}
Lieu: {metadata.get('location_city', 'N/A')} - {metadata.get('location_name', 'N/A')}
Cat√©gorie: {metadata.get('category', 'N/A')}
Description: {doc['text'][:400]}...
URL: {metadata.get('url', 'N/A')}
Score: {score:.3f}
"""
            context_parts.append(event_info.strip())
        
        return "\n\n".join(context_parts)
    
    def query(self, question: str, k: int = 10, min_score: float = 0.0) -> Dict:
        print(f"\nüîç Recherche pour : '{question}'")

        # 1) d√©tecter une ann√©e explicite
        year_filter = None
        m = re.search(r'\b(20\d{2})\b', question)
        if m:
            y = int(m.group(1))
            if 2000 <= y <= 2099:
                year_filter = y

        # 2) sur-√©chantillonner si on filtre par ann√©e (√©vite le 0 r√©sultat)
        k_raw = max(k, 10)
        if year_filter is not None:
            k_raw = max(k * 10, 200)  # <- cl√© : on prend large pour que le post-filtre trouve des 2024

        # IMPORTANT : on n'envoie PAS le filter FAISS ici, on filtre nous-m√™mes apr√®s
        results = self.vector_store.search(question, k=k_raw, filter_dict=None)

        # 3) filtrage c√¥t√© Python
        if year_filter is not None:
            results = [(doc, score) for (doc, score) in results
                    if doc["metadata"].get("year") == year_filter]

            # 4) fallback neutre si toujours vide : on relance une requ√™te simple
            if not results:
                neutral_q = f"√©v√©nement {year_filter}"
                print(f"‚ÑπÔ∏è Fallback neutre: '{neutral_q}'")
                results = self.vector_store.search(neutral_q, k=k_raw, filter_dict=None)
                results = [(doc, score) for (doc, score) in results
                        if doc["metadata"].get("year") == year_filter]

        # 5) seuil de score √©ventuel
        results = [(doc, score) for (doc, score) in results if score >= min_score]

        if not results:
            return {
                "question": question,
                "answer": "Je n'ai trouv√© aucun √©v√©nement correspondant √† votre recherche.",
                "sources": [],
                "context": "",
            }
            
        print(results)

        print(f"‚úì {len(results)} √©v√©nements pertinents trouv√©s")

        context = self._format_documents(results)
        print("ü§ñ G√©n√©ration de la r√©ponse...")
        messages = self.prompt_template.format_messages(context=context, question=question)
        response = self.llm.invoke(messages)
        answer = response.content
        print(f"‚úì R√©ponse g√©n√©r√©e ({len(answer)} caract√®res)")

        sources = [
            {
                "title": doc["metadata"].get("title", "N/A"),
                "city": doc["metadata"].get("location_city", "N/A"),
                "date": doc["metadata"].get("date_start", "N/A"),
                "url": doc["metadata"].get("url", "N/A"),
                "score": float(score),
            }
            for doc, score in results
        ]

        return {
            "question": question,
            "answer": answer,
            "sources": sources,
            "context": context,
            "num_sources": len(results),
        }
