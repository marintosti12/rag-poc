from mistralai import Mistral
import numpy as np
from typing import List, Dict
import json
import os
from dotenv import load_dotenv
import time

load_dotenv()

class MistralVectorizer:
    """Classe pour vectoriser avec l'API Mistral"""
    
    def __init__(self, api_key: str = None):
        """
        Initialise le vectorizer Mistral
        
        Args:
            api_key: Cl√© API Mistral (ou depuis .env)
        """
        self.api_key = api_key or os.getenv("MISTRAL_API_KEY")
        
        if not self.api_key:
            raise ValueError("MISTRAL_API_KEY non trouv√©e. Ajoutez-la dans .env")
        
        self.client = Mistral(api_key=self.api_key)
        self.model_name = "mistral-embed"
        self.embedding_dimension = 1024  # Dimension de mistral-embed
        
        print(f"‚úì Client Mistral initialis√©")
        print(f"  Mod√®le : {self.model_name}")
        print(f"  Dimension : {self.embedding_dimension}")
    
    def create_text_for_embedding(self, event: Dict) -> str:
        """
        Cr√©e un texte optimis√© pour l'embedding
        
        Args:
            event: Dictionnaire d'√©v√©nement
            
        Returns:
            Texte combin√©
        """
        parts = []
        
        if event.get('title'):
            parts.append(f"Titre: {event['title']}")
        
        if event.get('description'):
            # Limiter la description √† 500 caract√®res pour l'API
            desc = event['description'][:500]
            parts.append(f"Description: {desc}")
        
        if event.get('location_city'):
            parts.append(f"Lieu: {event['location_city']}")
        
        if event.get('location_name'):
            parts.append(f"√† {event['location_name']}")
        
        if event.get('keywords'):
            parts.append(f"Mots-cl√©s: {event['keywords']}")
        
        if event.get('category'):
            parts.append(f"Cat√©gorie: {event['category']}")
        
        return " | ".join(parts)
    
    def vectorize_events(self, 
                        events: List[Dict], 
                        batch_size: int = 10) -> np.ndarray:
        """
        Vectorise une liste d'√©v√©nements avec l'API Mistral
        
        Args:
            events: Liste d'√©v√©nements
            batch_size: Nombre d'√©v√©nements par batch (max 100 selon API)
            
        Returns:
            Array numpy de vecteurs
        """
        print(f"\nüî¢ Vectorisation de {len(events)} √©v√©nements avec Mistral...")
        
        # Cr√©er les textes
        texts = [self.create_text_for_embedding(event) for event in events]
        
        all_embeddings = []
        total_batches = (len(texts) + batch_size - 1) // batch_size
        
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            batch_num = i // batch_size + 1
            
            print(f"  Batch {batch_num}/{total_batches} : {len(batch)} textes...")
            
            try:
                # Appel API Mistral
                response = self.client.embeddings.create(
                    model=self.model_name,
                    inputs=batch
                )
                
                # Extraire les embeddings
                batch_embeddings = [item.embedding for item in response.data]
                all_embeddings.extend(batch_embeddings)
                
                print(f"  ‚úì Batch {batch_num} termin√©")
                
                # Pause pour respecter les limites de taux
                if i + batch_size < len(texts):
                    time.sleep(0.5)
                    
            except Exception as e:
                print(f"  ‚ùå Erreur sur batch {batch_num}: {e}")
                # En cas d'erreur, ajouter des vecteurs nuls
                for _ in range(len(batch)):
                    all_embeddings.append([0.0] * self.embedding_dimension)
        
        embeddings = np.array(all_embeddings, dtype=np.float32)
        print(f"‚úì Vectorisation termin√©e. Shape: {embeddings.shape}")
        
        return embeddings
    
    def save_embeddings(self, 
                       embeddings: np.ndarray, 
                       events: List[Dict],
                       output_dir: str = "data/processed"):
        """
        Sauvegarde les embeddings et m√©tadonn√©es
        
        Args:
            embeddings: Array numpy des vecteurs
            events: Liste des √©v√©nements
            output_dir: Dossier de sortie
        """
        os.makedirs(output_dir, exist_ok=True)
        
        # Sauvegarder les embeddings
        embeddings_path = os.path.join(output_dir, "mistral_embeddings.npy")
        np.save(embeddings_path, embeddings)
        print(f"‚úì Embeddings sauvegard√©s : {embeddings_path}")
        
        # Sauvegarder les m√©tadonn√©es
        metadata_path = os.path.join(output_dir, "events_metadata.json")
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(events, f, ensure_ascii=False, indent=2)
        print(f"‚úì M√©tadonn√©es sauvegard√©es : {metadata_path}")
        
        # Infos du mod√®le
        model_info = {
            'model_name': self.model_name,
            'embedding_dimension': self.embedding_dimension,
            'num_events': len(events),
            'shape': list(embeddings.shape)
        }
        
        model_info_path = os.path.join(output_dir, "model_info.json")
        with open(model_info_path, 'w', encoding='utf-8') as f:
            json.dump(model_info, f, indent=2)
        print(f"‚úì Infos du mod√®le sauvegard√©es : {model_info_path}")
    
    def test_connection(self):
        """Teste la connexion √† l'API Mistral"""
        try:
            response = self.client.embeddings.create(
                model=self.model_name,
                inputs=["test"]
            )
            print("‚úì Connexion √† l'API Mistral r√©ussie")
            return True
        except Exception as e:
            print(f"‚úó Erreur de connexion : {e}")
            return False


if __name__ == "__main__":
    import pandas as pd
    
    # Test de connexion
    print("üîå Test de connexion √† l'API Mistral...")
    vectorizer = MistralVectorizer()
    
    if not vectorizer.test_connection():
        print("‚ùå Impossible de se connecter. V√©rifiez votre cl√© API.")
        exit(1)
    
    # Charger les √©v√©nements
    print("\nüìÇ Chargement des √©v√©nements...")
    events_file = 'data/processed/events_clean.json'
    
    if not os.path.exists(events_file):
        print(f"‚ùå Fichier non trouv√© : {events_file}")
        exit(1)
    
    with open(events_file, 'r') as f:
        events = json.load(f)
    
    print(f"‚úì {len(events)} √©v√©nements charg√©s")
    
    # Vectoriser
    embeddings = vectorizer.vectorize_events(events, batch_size=10)
    
    # Sauvegarder
    vectorizer.save_embeddings(embeddings, events)
    
    print("\n‚úÖ Vectorisation avec Mistral termin√©e !")
    print(f"üìä Statistiques :")
    print(f"  - √âv√©nements : {len(events)}")
    print(f"  - Dimension : {embeddings.shape[1]}")
    print(f"  - Taille : {embeddings.nbytes / 1024 / 1024:.2f} MB")